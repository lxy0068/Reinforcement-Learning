@article{Kober2013,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@book{Fudenberg1998,
  title={The Theory of Learning in Games},
  author={Fudenberg, Drew and Levine, David K},
  year={1998},
  publisher={MIT Press}
}

@article{Mnih2015,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{Rumelhart1986,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}

@article{Sutton1988,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine Learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@phdthesis{Watkins1989,
  title={Learning from Delayed Rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  school={King's College, Cambridge}
}

@techreport{Rummery1994,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  year={1994},
  institution={University of Cambridge, Department of Engineering},
  number={CUED/F-INFENG/TR 166}
}